---
layout: post
title: 神经网络实例
categories: AIA
description: 几个神经网络实例的特点和实现方法
keywords: AI,神经网络
---

> 原创
> 
> 转载请注明出处，侵权必究。

# 1、经典网络
## 1.1 LeNet-5
针对灰度图片训练，图片只有一个颜色通道

输入0-9数字图片 - 卷积层 - 平均池化层 - 卷积层 - 平均池化层  - 全连接（两层） - softmax（10个输出）

约6万个参数

## 1.2 AlexNet

卷积层（可将图片缩小） - 最大池化层 - 最大池化层 - same卷积层 - same卷积层 - same卷积层 - 最大池化层 - 全连接层（两层）

约6000万个参数

使用了ReLU激活函数

## 1.3 VGG-16
包含16个卷积层和全连接层，1.38亿个参数

卷积层 - 池化层 - …… - 全连接（两层） - softmax

# 2、残差网络

a - linear - ReLU - linear - ReLU  ……
在a和a后面第二个RuLU前加一个a的直达

一个深度网络，随着层数增加，（训练效率减小）错误减小，后增加。如果加入了残差网络的直达通路，可能学习到的参数只有直达的部分有作用，W和b没有作用，所以不会影响网络的表现。

# 3、网络中的网络和1乘1卷积
不同的通道乘以不同的权重（1×1×通道个数）。

和池化层的不同：池化层不进行通道的压缩。1×1卷积要进行通道的压缩，压缩后是1×1卷积的个数。

# 4、Inception网络
网络决定需要1×1卷积层、3×3卷积层、5×5卷积层还是池化层等。

基本思想：
Inception 网络不需要人为决定使用哪个过滤器或者是否需要池化，而是由网络
自行确定这些参数，你可以给网络添加这些参数的所有可能值，然后把这些输出连接起来，
让网络自己学习它需要什么样的参数，采用哪些过滤器组合。

Inception网络，计算量大，通过使用1×1卷积层来简化计算。

大的图像 - 1×1卷积层（输出维度较小，即瓶颈层） - 卷积层

（计算量）<

大的图像 - 卷积层 ：

# 5、数据扩充
1、翻转图片

2、通道数值增加减少一定值

3、随机裁剪（出一个方框）


